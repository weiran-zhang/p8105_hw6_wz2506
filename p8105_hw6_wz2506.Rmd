---
title: "p8105_hw6_wz2506"
author: "Weiran Zhang"
date: "11/24/2019"
output: github_document
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)

##load packages
library(tidyverse)
library(readxl)
```


**Problem 1**

Load and clean the data
```{r}
##Load and clean the dataset
birthweight = read_csv("/Users/weiranzhang/Downloads/birthweight.csv") %>% 
janitor::clean_names() %>% 
  mutate(babysex = factor(recode(babysex,"1" = "male","2" = "famle" )),
        frace = factor(recode(frace,"1" = "White","2" = "Black" ,"3" = "Asian", "4"= "Puerto Rican","8"  = "Other", "9" = "Unknown")),
        mrace = factor(recode(mrace,"1" = "White","2" = "Black" ,"3" = "Asian", "4"= "Puerto Rican","8"  = "Other")),
        malform = factor(recode(malform,"0" = "absent","1" = "present")))

anyNA(birthweight) ##check for missing data

birthweight

```

Propose a regression model

By BIC model-building process
```{r}
##Fist check the full model
full_model = lm(bwt ~ ., data = birthweight)
summary(full_model)

full_model %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

By BIC model selection criterion
```{r}

BIC_model = step(full_model, direction = "backward",
                k = log(nrow(birthweight)), trace = FALSE)
summary(BIC_model)

BIC_model %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

Description of modeling process: 
The model-building process is based on BIC (Bayesian information criterion) which is a model selection method based on finite set of models and lower BIC value indicates a better model. 
So the best model we got by the BIC selection method shows that baby's sex, baby's head circumference at birth, baby’s length at birth, mother’s weight at delivery, gestational age in weeks, mother’s height, mother’s race, mother’s pre-pregnancy weight and average nomberof cigarettes smoked per day during pregnancy are appropriate predictors of the child's birth weight. 

Plot of model residuals against fitted values
```{r}

birthweight %>% 
  modelr::add_residuals(BIC_model) %>% 
  modelr::add_predictions(BIC_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + geom_line( y = 0, color = "red") +
  labs(
    x = "fitted values",
    y = "residuals",
    title = "residuals vs. fitted values"
  ) 
```

Compare model with two others
model 1: length at birth and gestational age as predictors
```{r}

model_1 = lm(bwt ~ blength + gaweeks, data = birthweight) 

model_1 %>% 
  broom::tidy() %>% knitr::kable()
```

model 2: head circumference, length, sex, and all interactions 
```{r}

model_2 = lm(bwt ~ bhead*blength + bhead*babysex + blength*babysex + bhead*babysex*blength,data = birthweight)

model_2 %>% 
  broom::tidy() %>% knitr::kable()
```

Cross-validation
```{r}

cv_df =
  modelr::crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(BIC_mod = map(train, ~BIC_model),
         model1_mod = map(train, ~model_1),
         model2_mod = map(train, ~model_2)) %>% 
  mutate(rmse_BIC = map2_dbl(BIC_mod, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_model_1= map2_dbl(model1_mod, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_model_2 = map2_dbl(model2_mod, test, ~modelr::rmse(model = .x, data = .y))
         )

cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

From the plot of rmse distribution, we can see that the rmse for model with only length at birth and gestational age as predictors has the highest rmse value among all three models, and the model with head circumference, length, sex and all interactions are the second highest and the BIC selected model has the lowest rmse which means it is the best model among all those three models. 


**Problem 2**

```{r}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}

boot_straps = 
  weather_df %>% 
  modelr::bootstrap(n = 5000)

bootstrap_results_1 = 
  boot_straps %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy),
    variables = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results,variables) 

```

Plot of $\hat{r}^2$
```{r}
bootstrap_results_1 %>% 
  ggplot(aes(x = r.squared))+ geom_density()+
  labs(title = "the distribution of r-squared",
       x = "r-squared")
```

From the plot, we can see a little bit left-skewed plot with light tail to the low values that may indicates that some outliers are included in the sample.

95% confidence interval for $\hat{r}^2$
```{r}

CI_1 = 
  bootstrap_results_1 %>% 
  filter(term == "tmin") %>% 
  pull(r.squared) %>% 
  quantile(c(0.025, 0.975))

CI_1

```

The 95% confidence interval for $\hat{r}^2$ is (0.8941060, 0.9270013)

Plot of $log(\hat{\beta_0}*\hat{\beta_1})$
```{r}

bootstrap_results_2 =
  bootstrap_results_1 %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    id_cols = .id,
    values_from = estimate,
    names_from = term
  ) %>% 
  janitor::clean_names() %>% 
  mutate(log_value = log(intercept*tmin)) 

bootstrap_results_2 %>% 
  ggplot(aes(x = log_value))+ geom_density()+
  labs(title = "the distribution of log(beta0_hat * beta1_hat)",
       x = "log(beta0_hat * beta1_hat)")
  
```

From the plot, we can see that a close to bell-shaped normal distributed plot which means that the distribution of $log(\hat{\beta_0}*\hat{\beta_1})$ basically follows normal distribution. 

```{r}

CI_2 = 
  bootstrap_results_2 %>% 
  pull(log_value) %>% 
  quantile(c(0.025, 0.975))

CI_2
```

The 95% confidence interval for $log(\hat{\beta_0}*\hat{\beta_1})$ is (1.965644, 2.059312) 